## Mq消息队列

### 消息队列的用途

1. 应用解耦：用户在订单系统中下单购买的，订单系统下游要接结算系统，营销系统等等，下游的变化不需要改变上游订单系统
2. 异步处理：蔚来存储描述数据
3. 流量消峰：秒杀，平抑上下游性能差异

### 消费队列基本概念

（所有MQ都会有这些概念）

+ 基本组成：主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。
+ 消费者组：由多个Consumer 实例构成。就是不同的下游业务。**同一条消息会在每个消费者组中下推一次（被消费一次）**
+ Topic：存储消息的逻辑队列（在实际中会分为不同的queue或者partition）

### RocketMQ

1. 基本模型

   <img src="/Users/yixia/Desktop/coding-experience/干死小公司妈的/图片/rocketmq.png"  style="zoom:30%" />

   NameServer: NameServer充当路由消息的提供者。生产者或消费者能够通过NameServer查找各topic相应的Broker IP列表。多个Nameserver实例组成集群，但相互独立，没有信息交换。

2. 基本概念

+ Broker：在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，
+ Topic：每个Topic的消息也可以分片存储于不同的 Broker。
+ Queue：用于存储消息的**物理地址**，每个Topic中的消息地址存储于多个Queue 中。

<img src="/Users/yixia/Desktop/coding-experience/干死小公司妈的/图片/3b6252fa-19df-4e11-9a54-221544f3521b.png"  style="zoom:30%"  />

3. 消息生产模式

   + 无序消息生产

     这个就是普通的生产者消费者模型

   + 有序消息生产

     这里说的是同一个topic下的有序消息生产

     字节内部是通过给一个message带一个partitionKey，然后把同样的partitionKey投放到同一个queue中（注意不是topic）实现的

   + 延迟消息生产

     这个有点像定时推送，比如主播安排完时间，要在开播前5分钟推送一条短信

   + Tag消息生产

     这个比较新，注意一下，这个Tag相当于同一个topic下的子topic，下游不同业务可以订阅一个topic然后消费不同的tag消息

4. RocketMQ存储的特点：

   + broker单个实例下所有的队列共用一个日志数据文件（全局CommitLog）来存储
   + 每个broker上面的queue保存了数据在commit log中的offset

   + 消费读取数据，需要先读取consumerQueue，再读取commit log，消息主体都是通过CommitLog来进行读写。写数据的时候也是实际写的是CommitLog，然后指定写queue里面的index（这样可以看出它实际上是顺序写）

5. RocketMQ的缺点及克服

   <https://www.jianshu.com/p/027accb2b7ae>

   顺序写，**随机读**。采用pagecache克服

6. 一些值得关注的主题：

   + 一个topic多个tag vs 多个topic

     这两个其实对于RocketMQ而言差不多，更多是业务上的选择，怎么合理怎么来，比如你topic太多，而实际上部分可以合并的，就可以选择使用一些单topic多tag。但是业务上差距很大的，你混在一起用多tag显然也不太合适

     

### Kafka

这是妈的最难的一个mq了

#### 消费机制

+ 消费者组与消费者

1. 同一个consumer group 的consumer可以消费不同topic的内容，相当于一个group.id 可以对应不同的 topic
2. 一个topic会有不同的分区，同一个分区可以被不同消费者组中的消费者消费，但这个分区在每一个消费者组中只能有一个对应的消费者。体会一下这迷人的逻辑。
3. 由2我们可知，消费者空余的情况只有一种，即在同一个consumer group里面消费某一个topic的消费者的数目大于了这个topic的分区数，这时在这个组里面会有消费者空余，但是如果不同的消费者组里面的消费这个topic的消费者数目超过了topic的分区数，这个是不会有空余的。

+ offset

1. 如何记录每个消费者消费到哪了很有意思，kafka有一个单独的topic叫__consumer_offsets，关于这个机制讲别的鸡巴玩意儿都没屌用，看一下它的key：`group.id+topic+分区号`，从这个key我们就可以看出，它记录的事实上是每一个分区被每一个消费者消费到哪的信息，又由于一个分区只能被一个消费者组中的一个消费者消费，所以这个key唯一确定了一个消费者消费的offset。这样的机制也保证了数据可以被多次消费，不需要消费了就删除。
2. __consumer_offset 还有别的作用，可见：<https://www.cnblogs.com/huxi2b/p/8316289.html>



## RocketMQ和Kafka的对比

### 架构区别

+ Kafka是一个broker上面的一个partition是一个文件，partition和queue是对应的（分别是Kafka和RocketMQ对应的）。相当于它是一个文件只存一种topic的一个partition的内容。但是RocketMQ是一个broker上面只有一个全局的commitLog，来存储消息，queue里面存的是索引。
+ 上面的差异带来了一个问题：rocketmq是顺序写消息，而kafka是随机写消息，这个磁盘读取开销不一样，rocketmq会快。而且kafka随着partition的增加，随机写会越来越严重。这就导致线上那些经常需要扩容的业务（比如下游一个消费者组，可能需要加queue）不能使用kafka。

### 选型问题

选择RocketMQ的常见业务特征

+ 生产时延、端到端延迟敏感，例如电商的订单系统、物流系统、抖音的IM端
+ 需要使用灵活的消息类型
  1. 发送defer消息，比如推送系统的直播间下推。
  2. 发送tag消息，比如binlog同步系统
  3. 下游灵活多变，海量的消费组，比如lark的会议视频系统

选择BMQ的常见业务特征

+ 时延不敏感，但吞吐量极大的业务，例如logCollector日志收集系统
+ 需要使用批式任务方式消费的业务：例如metric系统。（这个是因为它partition是一个hdfs目录，存的都是实实在在的文件）