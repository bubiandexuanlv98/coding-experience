##  同步，异步，阻塞，非阻塞区别

### 同步异步

1.     同步：调用时，在没有得到结果之前，该调用就不返回，**按照这个定义，绝大多数函数都是同步调用**。一般而言，我们在说同步、异步的时候，特指那些需要其他部件协作或者需要一定时间完成的任务。

2.     异步：调用者不会立刻得到结果，然后调用者会先处理别的工作。被调用方完成后，通过状态(效率低)、通知，或回调函数来告知调用者。随后调用者可以对被调用方传来的结果进行处理（也可以不处理，仅仅知晓即可）。

### 阻塞非阻塞

1. 阻塞：调用结果返回之前，当前线程会被挂起。socket的read/write/recv
2. 非阻塞：不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。

### 二者区别

本质区别：同步异步是如何通知的概念，阻塞和非阻塞是如何执行的概念，一般来说业务上讲同步异步的讨论场景，都是有两个线程之间需要通信或者互相通知。讲阻塞非阻塞一般讨论场景都是在一个线程内，当前线程调用服务时需不需要阻碍当前线程正常工作，不需要通知。如果非要讨论细致区别，那么就从IO系统调用入手去看：

1. 同步与阻塞的区别：同步当前线程还是激活的，只是从逻辑上当前函数没有返回而已，**但是阻塞就意味着当前线程刮起了**。
2. 异步与非阻塞的区别：非阻塞是立刻返回调用结果，这个结果可能不是完整结果，比如读取一个文件，非阻塞读取可能直接返回这个文件的一些元信息，**也就是说非阻塞可以返回一个不完整的信息**。异步不会立刻返回调用结果，即他不会返回一个不完整的结果，而是通过状态，通知，回调告知调用方。但是最终他的调用结果一定是完整的。
3. 同步非阻塞的情况：同步可能有一种轮询的方式，此时当前线程处于忙等待，并未挂起。**但是此时线程也不能处理别的**
4. 异步阻塞的情况：异步也会调用阻塞的函数，比如多个IO系统调用去read，然后各返回一个结果（这一步是非阻塞），然后用select 函数阻塞当前线程，监听所有**IO异步系统调用的结果** ，返回可读时再去read 

***这篇文章讲了所有需要的，尤其要看一下里面那个图***：<https://blog.csdn.net/penzo/article/details/5995834>，注意里面的图，左边如果没写“other processing”说明一直没有处理别的，尤其是那个Read()有那种分段的，那是想表达忙等待的意思

### 在IO模型中的二者

这里先看一下非阻塞和异步IO模型的区别：

异步IO（实际上是异步非阻塞AIO）

<img src="/Users/yixia/Desktop/coding-experience/干死小公司妈的/图片/2017-09-24-23-23-36.png"  style="zoom:60%"  />

非阻塞IO（实际上是同步非阻塞NIO）

<img src="/Users/yixia/Desktop/coding-experience/干死小公司妈的/图片/2017-09-24-23-19-53.png"  style="zoom:60%"  />

异步阻塞IO（多路复用IO）

<img src="/Users/yixia/Desktop/coding-experience/干死小公司妈的/图片/20190809100538991.png"  style="zoom:60%"  />



这个多路复用IO也就是我重构maitreya多路召回的时候用的，原来的使用的NIO，但是有一点区别，因为那个我并不是要读取调用的结果，我只要一个调用成功的通知

一个可以跟面试官聊的点：异步IO（非阻塞）和那些同步阻塞IO，同步非阻塞IO，多路IO，最关键的区别在于调用方是否要等待数据从内核态被复制到用户态，异步IO是不需要等待的，而同步IO，即使是同步非阻塞IO，多路IO都要等待这个

*GO如何实现非阻塞IO*

<https://blog.csdn.net/moxiaomomo/article/details/78529737>

## 多路复用IO

实现原理：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll监控的一个数据结构中，注意，实际上这些方法都是提供函数给用户态调用的，有时候用户态会有一个线程会轮询它们提供的一些函数，但是调用它们的函数的时候，这些函数会和内核有一些交互，实际上监控由内核监视，用户态只是轮询（比如epoll_wait）。

更详细：<https://baijiahao.baidu.com/s?id=1641172494287388070&wfr=spider&for=pc>

<https://www.cnblogs.com/aspirant/p/9166944.html>

1. select/poll/epoll三者的区别？

   - `select`：将文件描述符放入一个集合中，调用select时，将这个集合从用户空间拷贝到内核空间（缺点1：**每次都要复制，*开销大**），由内核根据就绪状态修改该集合的内容。（缺点2）**集合大小有限制**，32位机默认是1024（64位：2048）；**采用水平触发机制**。select函数返回后（实际上select把之前传入的fd_set**拷贝传出到用户态**并返回就绪的文件描述符总数），需要通过遍历这个集合，找到就绪的文件描述符（缺点3：**轮询的方式效率较低**），**当文件描述符的数量增加时，效率会线性下降；**
     1. select监控的fd_set，通过FD_SET把一个fd添加到这个监控中去，但调用select的时候用户应该是不能加监控的，因为fd_set已经被拷贝到内核去了
     2. 调用select函数的时候如果没有就绪的，就阻塞在那里，select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。对于select而言当有fd就绪以后select就返回了（其实其他都是如果有就绪就返回），**返回以后，需要通过遍历这个fd_set，才能找到就绪的文件描述符，不方便**。**而每次调用select的时候都要遍历fd_set，又是一个扫描**
     3. 根据1中的问题，当套接字比较多的时候，每次**调用**select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。**如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。**
   - `poll`：和select几乎没有区别，区别在于文件描述符的存储方式不同，poll采用链表的方式存储，没有最大存储数量的限制；
   - `epoll`：epoll使用mmap文件映射使内核和用户共享一片存储区域。加速与内核空间的消息传递（这个是错误的，可以show off to面试官）；支持的同时连接数上限很高（1G左右的内存支持10W左右的连接数）；文件描述符就绪时，内核采用回调机制，避免了轮询（内核会调用回调函数将就绪的描述符添加到一个链表中，执行epoll_wait时，返回这个链表）；支持水平触发和边缘触发，采用边缘触发机制时，只有活跃的描述符才会触发回调函数。
     1. 实际上epoll没有一个epoll函数（和select不一样），epoll是由好几个函数组成的，epoll_create用来创建一个epoll的实例，epoll_ctl用来注册fd，epoll_wait 用来返回就绪链表。这些函数可能是在内核态完成的，但是用户态会调用他们
     1. epoll_create 做了两件事情，它先在Linux内核空间（内核空间也是在内存里面）中申请一个文件系统（一切皆文件），然后建立一个红黑树用于存放socket句柄，然后建立一个双向链表做epoll_wait 的就绪链表。epoll_ctl在注册fd的时候就是把fd放到那颗红黑树里面，然后给每个fd注册一个回调函数，当fd上面出现就绪事件的时候，这个回调函数会启动，把fd放到那个就绪链表上面
     2. go里面的sysmon会轮询调用epoll_wait，来读取可读取数据的链表（然后用户态会重新调用读取数据的接口）
2. 什么是水平触发？什么是边缘触发？

   + 水平触发（LT，Level Trigger）模式下，只要一个文件描述符就绪，就会触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；
+ 边缘触发（ET，Edge Trigger）模式下，当描述符从未就绪变为就绪时通知一次，之后不会再通知，直到再次从未就绪变为就绪（缓冲区从不可读/写变为可读/写）。
   + 区别：边缘触发效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。
+ 为什么边缘触发一定要用非阻塞（non-block）IO：避免由于一个描述符的阻塞读/阻塞写操作让处理其它描述符的任务出现饥饿状态。因为边缘触发只触发一次，就意味着你读的时候一定要把数据读完才行

## 零拷贝

这个不错：<https://blog.csdn.net/hellozhxy/article/details/115312608>

## 乐观锁，悲观锁，自旋锁，互斥锁

悲观锁：对于并发控制而言，我们平时用的锁（synchronized，Lock）是一种悲观的策略。它总是假设每一次临界区操作会产生冲突，因此，必须对每次操作都小心翼翼。如果多个线程同时访问临界区资源，一个线程得到锁，其他需要锁的线程就挂起的情况就是[悲观锁](https://so.csdn.net/so/search?q=悲观锁&spm=1001.2101.3001.7020)。

乐观锁（CAS操作）：与之相对的有一种乐观的策略，它会假设对资源的访问是没有冲突的。既然没有冲突也就无需等待了，所有的线程都在不停顿的状态下持续执行。那如果遇到问题了无锁的策略使用一种叫做比较交换（CAS Compare And Swap）来鉴别线程冲突，一旦检测到冲突产生，**就重试当前操作直到没有冲突**。CAS操作是非阻塞的，它对死锁问题天生免疫，而且它比基于锁的方式拥有更优越的性能。

自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待（忙等待），然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。可以看出它是一种乐观锁。spinlock基于CAS操作。golang自旋锁实现：<https://www.cnblogs.com/yizhou35/p/13729138.html>

互斥锁（mutual lock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，这里会发生一次用户态陷入到内核态，然后该线程被挂起，内核来帮我们切换线程，内核在切换线程的时候需要保存一些当前线程独有的数据，就是TCB结构中的数据

CAS操作：中文叫做比较和交换，其实就是指atomic包里面的比较并交换的那一组接口。atomic里面有一组原子操作，CPU指令级别的，包括修改操作，比较并交换操作等。

+ 原理（基于JAVA的多线程）：一个线程间共享的变量，首先在主存中会保留一份，然后每个线程的工作内存也会保留一份副本。这里说的预期值，就是线程保留的副本。当该线程从主存中获取该变量的值后，主存中该变量可能已经被其他线程刷新了，但是该线程工作内存中该变量却还是原来的值，这就是所谓的预期值了。当你要用 CAS刷新该值的时候，如果发现线程工作内存和主存中不一致了，就会失败，如果一致，就可以更新成功。
  

<https://mp.weixin.qq.com/s?__biz=MzkwMDE1MzkwNQ==&mid=2247496062&idx=1&sn=c04e0b83f38c45d06538ebac69529ee1&source=41#wechat_redirect>



## 设计模式

### 工厂模式

<https://blog.csdn.net/a745233700/article/details/120253639>

#### 简单工厂模式

适用场景：

- 工厂类负责创建的对象比较少，由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂
- 客户端只知道传入工厂类的参数，对于如何创建对象并不关心

优缺点：在上面那个链接里面，核心就是不符合开闭原则

不同工厂模式的区别：

（1）简单工厂模式有一个抽象产品类和一个具体工厂类，抽象产品类可以派生出多个具体产品类，但工厂只有一个，不会派生新的，所有具体产品类都是由那一个具体工厂类创建的，**根据传到具体工厂的参数不同来生成不同的具体产品**

（2）工厂方法只有一个抽象产品类和一个抽象工厂类，但可以派生出多个具体产品类和具体工厂类，每个具体工厂类只能创建一个具体产品类的实例。

（3）抽象工厂模式拥有多个抽象产品类（产品族）和一个抽象工厂类，每个抽象产品类可以派生出多个具体产品类；抽象工厂类也可以派生出多个具体工厂类，同时每个具体工厂类可以创建多个具体产品类的实例


tabby层与层算不算是工厂方法模式呢？不算，因为既没有一个抽象的工厂，也没有一个具体的工厂，产品倒是有一个“抽象产品类”

## 设计原则

1. 开放封闭原则：https://blog.csdn.net/coderinchina/article/details/50458635。核心就是：在设计一个模块时，应当使得这个模块可以在不被修改的前提下被扩展(这就要求我们不能在一个类中写死所有的功能)

## 建堆

1. 设计模式
2. 分布式，主从数据同步
3. 中断

## 普通hash，一致性hash，hash槽

1. 普通hash表与一致性hash表：<https://zhuanlan.zhihu.com/p/24440059>

   区别概括一下，在于扩容的时候（扩容指的是增加可盛放kv对的空间的时候）需不需要rehash，或者说需不需要调整所有kv对的位置。普通hash是需要的，golang里面的map（https://hackernoon.com/some-insights-on-maps-in-golang-rm5v3ywh）在扩容的时候是需要rehash的，包括redis的kv对在扩容迁移的时候需要rehash。但是一致性hash就不需要，无论是增加一个桶（机器）还是删除一个桶（机器）都不需要rehash，只需要调整两个桶中的kv对分布即可

   https://www.cnblogs.com/HDMaxfun/p/15711892.html 这个看个乐，展示一致性hash的删除和增加的过程很清晰，但是注意redis cluster并没有使用一致性hash

2. 一致性hash与hash槽

   + 首先声明一下：redis cluster用的是hash槽而不是一致性hash

   + hash槽长什么样：https://time.geekbang.org/column/article/276545 这个就是redis cluster里面的实现

   + 为啥redis cluster使用hash槽而不使用一致性hash：https://wenku.baidu.com/view/79f7e44c7b3e0912a21614791711cc7930b77857.html。

     其实核心就两点：

     1. 一个是hash槽可以保证数据分布更均匀，不会出现太明显的数据倾斜，尤其在桶（机器）比较少的时候，一致性hash的数据倾斜更严重（不过后面出现了虚拟节点，有效的解决了这个问题）。

     2. 第二个也是非常关键的一点：一致性hash会导致循环雪崩（一般是热key）或者造成请求堆积到后面的mysql，这是因为当一个机器宕机以后，在没有优化的情况下（国内的codis就是一个优化后的一致性hash）发到集群的key会直接查询这台机器的下一台机器（一致性hash的索引过程）

   
